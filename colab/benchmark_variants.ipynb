{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sile16/pgx/blob/master/colab/benchmark_variants.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# PGX Performance Benchmark: 2048 & Backgammon Variants\n",
    "\n",
    "This notebook benchmarks GPU-optimized variants of 2048 and Backgammon.\n",
    "\n",
    "**Optimizations tested:**\n",
    "- **Branchless operations**: Replace `jax.lax.cond` with `jnp.where`\n",
    "- **No rotations**: Eliminate `jnp.rot90` memory shuffles\n",
    "- **Fast observation**: Minimal observation (34 vs 86 elements)\n",
    "- **Combined**: All optimizations together\n",
    "\n",
    "**Instructions:**\n",
    "1. Select GPU runtime: `Runtime > Change runtime type > GPU`\n",
    "2. Run all cells: `Runtime > Run all`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup_header"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": "# Clone the repository with optimized variants (master branch)\n!git clone --branch master https://github.com/sile16/pgx.git\n%cd pgx"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": "# Install pgx from local source and monitoring dependencies\n!pip install . gputil psutil"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_device"
   },
   "outputs": [],
   "source": [
    "# Detect and display device information\n",
    "import jax\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DEVICE INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# JAX info\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"JAX devices: {jax.devices()}\")\n",
    "print()\n",
    "\n",
    "# Get detailed device info\n",
    "device = jax.devices()[0]\n",
    "device_kind = device.device_kind\n",
    "platform = device.platform\n",
    "\n",
    "if platform == 'gpu':\n",
    "    # Get NVIDIA GPU details\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=name,memory.total,driver_version', '--format=csv,noheader'],\n",
    "            capture_output=True, text=True\n",
    "        )\n",
    "        gpu_info = result.stdout.strip()\n",
    "        gpu_name, gpu_memory, driver = [x.strip() for x in gpu_info.split(',')]\n",
    "        print(f\"GPU Name: {gpu_name}\")\n",
    "        print(f\"GPU Memory: {gpu_memory}\")\n",
    "        print(f\"NVIDIA Driver: {driver}\")\n",
    "    except:\n",
    "        print(f\"GPU: {device_kind}\")\n",
    "        \n",
    "elif platform == 'tpu':\n",
    "    # TPU info\n",
    "    print(f\"TPU Type: {device_kind}\")\n",
    "    print(f\"TPU Devices: {len(jax.devices())}\")\n",
    "    # Try to get more TPU info\n",
    "    try:\n",
    "        tpu_name = os.environ.get('TPU_NAME', 'Unknown')\n",
    "        print(f\"TPU Name: {tpu_name}\")\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(f\"Device: {device_kind} ({platform})\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Store device info for results\n",
    "DEVICE_SUMMARY = f\"{platform}:{device_kind}\"\n",
    "print(f\"\\nDevice Summary: {DEVICE_SUMMARY}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Start GPU/resource monitoring (optional - provides live metrics dashboard)\n# This sends metrics to an external service for visualization\ntry:\n    import GPUtil\n    import psutil\n    from threading import Thread\n    from time import sleep\n    import requests\n\n    class SimpleGPUMonitor:\n        \"\"\"Simple GPU monitor that prints stats periodically.\"\"\"\n        def __init__(self, interval=30):\n            self.interval = interval\n            self._running = False\n            self._thread = None\n\n        def _loop(self):\n            while self._running:\n                try:\n                    gpus = GPUtil.getGPUs()\n                    if gpus:\n                        gpu = gpus[0]\n                        print(f\"[GPU Monitor] {gpu.name}: {gpu.load*100:.1f}% load, \"\n                              f\"{gpu.memoryUsed:.0f}/{gpu.memoryTotal:.0f} MB ({gpu.memoryUtil*100:.1f}%)\")\n                except:\n                    pass\n                sleep(self.interval)\n\n        def start(self):\n            self._running = True\n            self._thread = Thread(target=self._loop, daemon=True)\n            self._thread.start()\n            print(f\"GPU monitoring started (updates every {self.interval}s)\")\n            return self\n\n        def stop(self):\n            self._running = False\n\n    # Start monitoring\n    gpu_monitor = SimpleGPUMonitor(interval=30).start()\nexcept Exception as e:\n    print(f\"GPU monitoring not available: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "benchmark_header"
   },
   "source": "## 2. Run Benchmark\n\nThe benchmark will:\n1. Test all 2048 variants (original, branchless, no_rotate, all)\n2. Test all Backgammon variants (original, fast_obs, branchless, all)\n3. Output speedup comparisons"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_benchmark"
   },
   "outputs": [],
   "source": "# Run the full benchmark\n# - batch_size=4000 works well for T4/V100/A100 GPUs\n# - num_batches=5 for 2048 (fast game)\n# - bg_batches=2 for backgammon (slower, uses fewer batches to keep <15min total)\n# - skip_validation speeds up the benchmark (validation already done on CPU)\n\n!python benchmarks/benchmark_all_variants.py \\\n    --batch-size 4000 \\\n    --num-batches 5 \\\n    --bg-batches 2 \\\n    --skip-validation \\\n    --output-json benchmark_results.json"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "# Display results as a formatted table\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "with open('benchmark_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Get GPU name for header\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=name', '--format=csv,noheader'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    gpu_name = result.stdout.strip()\n",
    "except:\n",
    "    gpu_name = results['device']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"BENCHMARK RESULTS - {gpu_name}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Device: {results['device']}\")\n",
    "print(f\"JAX: {results['jax_version']}\")\n",
    "print(f\"Batch size: {results['config']['batch_size']}\")\n",
    "print()\n",
    "\n",
    "# 2048 Results\n",
    "print(\"2048 Performance:\")\n",
    "print(f\"{'Variant':<15} {'Games/sec':>12} {'Steps/sec':>14} {'Speedup':>10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "baseline_2048 = results['benchmarks']['2048_original']['games_per_second']\n",
    "for variant in ['original', 'branchless', 'no_rotate', 'all']:\n",
    "    key = f'2048_{variant}'\n",
    "    if key in results['benchmarks']:\n",
    "        data = results['benchmarks'][key]\n",
    "        speedup = data['games_per_second'] / baseline_2048\n",
    "        print(f\"{variant:<15} {data['games_per_second']:>12,.1f} {data['steps_per_second']:>14,.1f} {speedup:>9.2f}x\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Backgammon Results\n",
    "print(\"Backgammon Performance:\")\n",
    "print(f\"{'Variant':<15} {'Games/sec':>12} {'Steps/sec':>14} {'Speedup':>10}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "baseline_bg = results['benchmarks']['backgammon_original']['games_per_second']\n",
    "for variant in ['original', 'fast_obs', 'branchless', 'all']:\n",
    "    key = f'backgammon_{variant}'\n",
    "    if key in results['benchmarks']:\n",
    "        data = results['benchmarks'][key]\n",
    "        speedup = data['games_per_second'] / baseline_bg\n",
    "        print(f\"{variant:<15} {data['games_per_second']:>12,.1f} {data['steps_per_second']:>14,.1f} {speedup:>9.2f}x\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Print copy-pasteable summary\n",
    "print(\"\\nðŸ“‹ COPY-PASTE SUMMARY:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"Device: {gpu_name}\")\n",
    "print(f\"Batch size: {results['config']['batch_size']}\")\n",
    "print()\n",
    "print(\"2048:\")\n",
    "for variant in ['original', 'branchless', 'no_rotate', 'all']:\n",
    "    key = f'2048_{variant}'\n",
    "    if key in results['benchmarks']:\n",
    "        data = results['benchmarks'][key]\n",
    "        speedup = data['games_per_second'] / baseline_2048\n",
    "        print(f\"  {variant}: {data['games_per_second']:,.0f} games/sec ({speedup:.2f}x)\")\n",
    "\n",
    "print()\n",
    "print(\"Backgammon:\")\n",
    "for variant in ['original', 'fast_obs', 'branchless', 'all']:\n",
    "    key = f'backgammon_{variant}'\n",
    "    if key in results['benchmarks']:\n",
    "        data = results['benchmarks'][key]\n",
    "        speedup = data['games_per_second'] / baseline_bg\n",
    "        print(f\"  {variant}: {data['games_per_second']:,.0f} games/sec ({speedup:.2f}x)\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "custom_header"
   },
   "source": [
    "## 3. Custom Benchmark (Optional)\n",
    "\n",
    "Run with different batch sizes to find optimal throughput:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "custom_benchmark"
   },
   "outputs": [],
   "source": [
    "# Uncomment to run with different batch sizes\n",
    "# !python benchmarks/benchmark_all_variants.py --batch-size 1000 --num-batches 3 --skip-validation\n",
    "# !python benchmarks/benchmark_all_variants.py --batch-size 2000 --num-batches 3 --skip-validation\n",
    "# !python benchmarks/benchmark_all_variants.py --batch-size 8000 --num-batches 3 --skip-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "individual_header"
   },
   "source": [
    "## 4. Individual Game Benchmarks (Optional)\n",
    "\n",
    "Run the original individual benchmarks for comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark_2048_original"
   },
   "outputs": [],
   "source": [
    "# 2048 original benchmark\n",
    "# !python benchmarks/benchmark_2048.py --batch-sizes 1000,2000,4000 --num-batches 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark_backgammon_original"
   },
   "outputs": [],
   "source": [
    "# Backgammon original benchmark\n",
    "# !python benchmarks/benchmark_backgammon.py --batch-sizes 1000,2000,4000 --num-batches 3 --short-game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpu_header"
   },
   "source": [
    "## 5. TPU Benchmark (if available)\n",
    "\n",
    "To run on TPU:\n",
    "1. Change runtime to TPU: `Runtime > Change runtime type > TPU`\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpu_setup"
   },
   "outputs": [],
   "source": [
    "# Uncomment for TPU setup\n",
    "# import jax.tools.colab_tpu\n",
    "# jax.tools.colab_tpu.setup_tpu()\n",
    "# print(f\"TPU devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpu_benchmark"
   },
   "outputs": [],
   "source": [
    "# Uncomment for TPU benchmark (use smaller batch size)\n",
    "# !python benchmarks/benchmark_all_variants.py --batch-size 2000 --num-batches 5 --skip-validation"
   ]
  }
 ]
}